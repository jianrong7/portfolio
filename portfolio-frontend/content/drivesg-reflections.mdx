---
title: "DriveSG - Reflections"
subtitle: Follow along as I reflect on my journey building a native application using React Native.
date: "2021-08-30T08:00:00.000Z"
updated: "2021-08-30T08:00:00.000Z"
categories: []
keywords: ["react native", "self-improvement"]
slug: drivesg-reflections
type: "blogPost"
colorFeatured: "linear-gradient(104.01deg, #9BEBEB 5.51%, #0FA6E9 98.93%)"
featured: false
readTime: "2 min read"
---

# **ğŸ“** DriveSG Reflections

## ğŸ”‘ Why I started building this app

IÂ wantedÂ toÂ workÂ onÂ aÂ projectÂ usingÂ myÂ newlyÂ learntÂ [ReactÂ Native](https://reactnative.dev/)Â skills from [Full Stack Open](https://fullstackopen.com/en/).Â AtÂ thatÂ time,Â IÂ wasÂ alsoÂ practicingÂ forÂ driving theoryÂ testsÂ inÂ Singapore.Â The process was pretty boring. It goes something like this.

1. Read the Highway code book
2. Search up the Internet for [practice resources](https://www.tptest.sg/)
3. Sign up for practice tests
4. Go for the test

Since I managed to get additional resources, I thought I could make them into extra practice for people like me, who want to do the test at the convenience of their home or anywhere they are. That would give people more confidence when they were actually going to do the actual test.

IÂ thoughtÂ thatÂ thisÂ appÂ wouldÂ beÂ aÂ greatÂ combinationÂ ofÂ bothÂ worlds.Â IÂ getÂ toÂ practiceÂ myÂ RN skillsÂ whileÂ helpingÂ outÂ othersÂ whoÂ wantedÂ toÂ getÂ theirÂ drivingÂ license.

## ğŸ—ï¸ How I built it

### Front End

IÂ builtÂ thisÂ usingÂ [ReactÂ Native](https://reactnative.dev/),Â throughÂ theÂ [ExpoÂ CLI](https://docs.expo.dev/index.html).Â IÂ haveÂ beenÂ learningÂ frontendÂ developmentÂ forÂ almostÂ halfÂ aÂ yearÂ now.Â WhenÂ IÂ heardÂ thatÂ IÂ couldÂ useÂ myÂ [React.js](https://reactjs.org/)Â skillsÂ toÂ createÂ aÂ mobileÂ app,Â IÂ gotÂ veryÂ excited.Â However,Â afterÂ goingÂ throughÂ someÂ tutorials,Â IÂ realizeÂ theÂ limitationsÂ ofÂ thatÂ butÂ IÂ decidedÂ thatÂ itÂ wasÂ stillÂ goodÂ enoughÂ forÂ myÂ not-so-complicated app.Â IÂ wantedÂ toÂ useÂ itÂ toÂ showcaseÂ myÂ skillsÂ afterÂ goingÂ throughÂ [TheÂ OdinÂ Project](https://www.theodinproject.com/) andÂ [FullÂ StackÂ Open](https://fullstackopen.com/en/).

The routing and navigation was largely handled by [React Navigation](https://reactnavigation.org/). Although it offered pretty good UI and functionality out of the box, I was a bit limited by its customizability. I still stuck with it because I felt like the trade-off was fair and it got the app up and running very quickly. In the end, I am glad I used the library, my experience with it was generally positive although I still cannot remove the border from the header after scrolling through countless of [Github threads](https://github.com/react-navigation/react-navigation/issues/865).

### Back End

When I was deciding what to use for my backend, I originally wanted to build my own REST API usingÂ [Express](https://expressjs.com/)Â andÂ [MongoDB](https://www.mongodb.com/). I thought that it would be helpful because others could potentially fetch data from the API in the future when they want to create their own application. I even thought about using [GraphQL](https://graphql.org/). In the end, however, I used neither. GraphQL was overkill because this app did not require me to worry about over or underfetching of data. I only needed to fetch 50 questions and answers every time the user attempts a test.

Keeping in mind that I wanted the application quickly up and running, I decided to useÂ [Firebase](https://firebase.google.com/). Its simplicity made the development process a breeze and I am glad I picked a BaaS to complete this project. In the future, maybe I will look into creating my own REST API which can be more flexible.

## ğŸ˜” Problems I faced

### Extracting text from image

OneÂ ofÂ theÂ biggestÂ problemsÂ IÂ facedÂ wasÂ extractingÂ theÂ textÂ fromÂ images.Â OriginallyÂ allÂ myÂ questionsÂ areÂ inÂ imageÂ format.Â ThisÂ meantÂ thatÂ IÂ hadÂ toÂ findÂ aÂ wayÂ toÂ extractÂ textÂ fromÂ images.Â Naturally,Â GoogleÂ toldÂ meÂ toÂ use OpticalÂ CharacterÂ RecognitionÂ (OCR)Â technology.Â MyÂ firstÂ thoughtÂ wasÂ toÂ goÂ findÂ aÂ JSÂ libraryÂ thatÂ doÂ justÂ that.Â InÂ theÂ end,Â IÂ used [Tesseract.js](https://tesseract.projectnaptha.com/).Â IÂ thoughtÂ theÂ magicalÂ AIÂ toolsÂ canÂ helpÂ meÂ extractÂ myÂ textÂ perfectly.Â Boy,Â howÂ wrongÂ wasÂ I.

TheÂ textÂ extractedÂ hadÂ lotsÂ ofÂ emptyÂ spacesÂ andÂ gibberishÂ becauseÂ theÂ textÂ wereÂ sparseÂ andÂ theirÂ fontsÂ wereÂ alsoÂ inconsistent.Â IÂ wentÂ toÂ searchÂ upÂ onÂ howÂ toÂ improveÂ theÂ accuracyÂ ofÂ myÂ resultsÂ andÂ severalÂ suggestionsÂ pointedÂ meÂ toÂ useÂ OpenCV.Â IÂ thoughtÂ aboutÂ divingÂ downÂ theÂ rabbitÂ holeÂ ofÂ ArtificalÂ Intelligence,Â butÂ IÂ realisedÂ thatÂ wasÂ notÂ myÂ goal.Â MyÂ goalÂ wasÂ toÂ createÂ aÂ workingÂ prototypeÂ quicklyÂ andÂ itÂ didÂ notÂ needÂ toÂ beÂ 100%Â accurate.

InÂ theÂ end,Â IÂ usedÂ aÂ veryÂ crudeÂ methodÂ ofÂ dividingÂ allÂ theÂ imagesÂ intoÂ severalÂ rectanglesÂ andÂ usedÂ Tesseract.jsÂ toÂ extractÂ theÂ textÂ forÂ me.Â TheÂ results,Â thoughÂ notÂ perfect,Â wereÂ muchÂ better.

### Cropping images from an image

AnotherÂ problemÂ IÂ facedÂ wasÂ tryingÂ toÂ getÂ theÂ imagesÂ fromÂ theÂ questions.Â AsÂ someÂ questionsÂ hadÂ images,Â IÂ hadÂ toÂ doÂ aÂ massÂ croppingÂ ofÂ theÂ images.Â IÂ thoughtÂ aboutÂ usingÂ CropperJSÂ butÂ inÂ theÂ endÂ IÂ foundÂ aÂ shorterÂ workaroundÂ ofÂ usingÂ Photoshop'sÂ AutomateÂ BatchÂ jobs.Â ItÂ didÂ theÂ trickÂ afterÂ watchingÂ aÂ tutorialÂ video.

### Linking pictures from Storage to Firestore

As Firebase Storage did not support NodeJS, I faced a problem in linkingÂ theÂ imagesÂ fromÂ FirebaseÂ StorageÂ toÂ myÂ questionsÂ inÂ CloudÂ Firestore. InÂ theÂ end,Â IÂ foundÂ aÂ workaroundÂ wherebyÂ IÂ listedÂ allÂ theÂ filesÂ inÂ FirebaseÂ StorageÂ andÂ thenÂ usedÂ NodeJSÂ toÂ updateÂ theÂ documentsÂ inÂ FirestoreÂ withÂ theÂ imageÂ links.

## ğŸ“• What I learnt

Applying the technologyÂ inÂ realÂ lifeÂ isn'tÂ asÂ straightforwardÂ asÂ IÂ thought.Â ThereÂ areÂ manyÂ problemsÂ thatÂ willÂ come upÂ unexpectedlyÂ alongÂ theÂ way.Â AsÂ muchÂ asÂ possible,Â planÂ outÂ theÂ architectureÂ ofÂ theÂ project,Â butÂ beÂ mentallyÂ readyÂ andÂ flexibleÂ enoughÂ toÂ learnÂ newÂ technologiesÂ (Photoshop, Figma)Â toÂ solveÂ theÂ problemsÂ atÂ hand.

ThisÂ projectÂ alsoÂ taughtÂ meÂ thatÂ oneÂ developerÂ aloneÂ canÂ actuallyÂ completeÂ aÂ lotÂ butÂ itÂ isÂ alsoÂ notÂ theÂ mostÂ idealÂ becauseÂ IÂ keptÂ asking my friends for opinions, whether it was related to its design or its functionality.

Also,Â theÂ lastÂ 10%Â ofÂ theÂ projectÂ tookÂ upÂ 90%Â ofÂ myÂ time.Â ThingsÂ likeÂ fixing bugs, removing input error, making the buttons recognize a touch slightly out of the button.Â TheseÂ thingsÂ takeÂ upÂ theÂ mostÂ time.Â AlthoughÂ theyÂ doÂ notÂ add significantlyÂ toÂ theÂ coreÂ functionalityÂ ofÂ theÂ app,Â theyÂ contribute massively to theÂ userÂ experience.

This was also my first time pushing an application to the Google Play Store. Thanks to Expo CLI, I got the App Bundle relatively quickly, however, the process of reviewing the app and getting the actual working product uploaded to the app store was relatively slow. It taught me the importance of planning as well as the emphasis on testing the application before the actually publishing the application.

## ğŸ¤” What's next?

DriveSGÂ isÂ definitelyÂ notÂ aÂ completeÂ product.Â ThereÂ areÂ stillÂ certainÂ placesÂ thatÂ IÂ willÂ touchÂ upÂ hereÂ andÂ there.Â ButÂ itÂ isÂ mostlyÂ usableÂ andÂ canÂ beÂ consideredÂ aÂ MinimumÂ ViableÂ ProductÂ (MVP).

LikeÂ whatÂ SherylÂ SandbergÂ said,Â "DoneÂ isÂ betterÂ thanÂ perfect."

IÂ amÂ gladÂ toÂ beÂ ableÂ toÂ shipÂ theÂ appÂ toÂ production.Â TheÂ jobÂ isÂ done,Â butÂ itÂ isÂ farÂ fromÂ perfect.

- Implement my own backend using Express.js and MongoDB
- User authentication system to save history of user attempts

## ğŸ Getting the iOS version running

One of the main reasons I used React Native was because I wanted a mobile application which worked on both Android and iOS devices while sharing a common codebase. Thankfully, the process was very smooth, largely because this application is not very heavy but also because the Expo CLI made the process much smoother with their detailed guides. Within an hour, I could get the production application up and running on the iOS simulator. It was really fascinating to see my application working on two completely different platforms.

The React Native team is doing a great job and I would definitely use React Native more in the future. Being able to transfer my React and JavaScript knowledge directly into building a mobile application is really convenient, and I think most developers believe that developer experience triumphs all.

Although the React Native hype is no longer as great, the RN team has still been very active, keeping RN updated and consistently posting their vision for RN. It is also nice to see that RN is being used by parts of the Facebook application, showing that it is still feasible to use RN for a large scale application across platforms. In tandem with [Facebook's vision to become 'a metaverse company'](https://www.theverge.com/22588022/mark-zuckerberg-facebook-ceo-metaverse-interview), the RN developers are also trying to make RN for VR. With the competition from Flutter, the RN team continues to show their determination to continuously innovate on their framework and improve it.

### Technologies used

- React Native
  - React Navigation
  - React Native Progress
  - Expo CLI
- Firebase
  - Cloud Firestore
  - Storage
- Figma
  - To design logo and splash screen
- Photoshop
  - To crop multiple images
- Tesseract.js
  - Used OCR to extract text from images
